{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_tutorial_pytorch",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPYQneaIQL6IxDj3J9d4Zj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theMADAIguy/STOCK-PREDICTION-USING-SVM-REGRESSION/blob/master/text_tutorial_pytorch_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKjR8Bh1QODN",
        "colab_type": "code",
        "outputId": "5c52f236-d6af-4917-bf48-4c5ab86e2021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#Constants\n",
        "SEED = 1234\n",
        "BATCH_SIZE=64\n",
        "EPOCHS=10\n",
        "\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/\n",
        "PATH = './text_rnn_model.pt'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uylqyn0CcrUi",
        "colab_type": "code",
        "outputId": "fefba50c-4765-4cbc-8ea1-87173e1a0c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "TEXT=data.Field(tokenize='spacy', include_lengths=True)\n",
        "LABEL=data.LabelField(dtype=torch.float)\n",
        "\n",
        "trainSet, testSet = datasets.IMDB.splits(TEXT, LABEL)\n",
        "testSet, validSet = testSet.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 197k/84.1M [00:00<00:50, 1.66MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 63.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs6-2PkvNNZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d2b895e7-eeac-40b9-b209-465e3417efcd"
      },
      "source": [
        "TEXT.build_vocab(trainSet, max_size= MAX_SIZE_VOCAB, vectors='glove.6B.100d', unk_init=torch.Tensor.normal_)\n",
        "LABEL.build_vocab(trainSet)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.23MB/s]                           \n",
            "100%|█████████▉| 399533/400000 [00:15<00:00, 26665.18it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPberGlEO9HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((trainSet, validSet, testSet), batch_size=BATCH_SIZE, device=device, sort_within_batch=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGc-u17rfL5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, vocab_size, dropout, bidirectional, n_layers, pad_idx):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding=nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "    self.rnn=nn.LSTM(embedding_dim, hidden_dim,num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "    self.fc=nn.Linear(hidden_dim * 2, output_dim)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text, text_lenghts):\n",
        "    embedded=self.dropout(self.embedding(text))\n",
        "    packed_embedding=nn.utils.rnn.pack_padded_sequence(embedded, text_lenghts)\n",
        "    output, (hidden, cell)=self.rnn(packed_embedding)\n",
        "    hidden=self.dropout(torch.cat((hidden[-1,:,:], hidden[-2,:,:]), dim=1))\n",
        "    return self.fc(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1yEIky0g2Y0",
        "colab_type": "code",
        "outputId": "3af3be38-5bf2-4d57-e106-7f20fc67114d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "INPUT_DIMENSION=len(TEXT.vocab)\n",
        "EMBEDDING_DIMENSION=100\n",
        "HIDDEN_DIMENSION=256\n",
        "OUTPUT_DIMENSION=1\n",
        "DROPOUT=0.5\n",
        "BIDIRECTIONAL=True\n",
        "N_LAYERS=2\n",
        "PAD_IDX=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "MAX_SIZE_VOCAB=25002\n",
        "\n",
        "model=RNN(INPUT_DIMENSION,EMBEDDING_DIMENSION, HIDDEN_DIMENSION, OUTPUT_DIMENSION, MAX_SIZE_VOCAB, DROPOUT, BIDIRECTIONAL, N_LAYERS, PAD_IDX)\n",
        "print(model)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FznT3BYHrZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f255f37-87f4-4c33-bfd0-3ecf0158e7a3"
      },
      "source": [
        "pre_trained_embedding=TEXT.vocab.vectors\n",
        "print(pre_trained_embedding.shape)\n",
        "model.embedding.weight.data.copy_(pre_trained_embedding)\n",
        "UNK_IDX=TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX]=torch.zeros(EMBEDDING_DIMENSION)\n",
        "model.embedding.weight.data[PAD_IDX]=torch.zeros(EMBEDDING_DIMENSION)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZvk5RCNiSRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optim.Adam(model.parameters())\n",
        "criterion=nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6BBcfXpkDrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0_eOFP9vB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(predicted, labels):\n",
        "\n",
        "  rounded=torch.round(torch.sigmoid(predicted))\n",
        "  correct=(rounded==labels).float()\n",
        "  acc=correct.sum()/len(rounded)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKN7DxC9BlQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss=0.0\n",
        "  epoch_acc=0.0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, text_lengths = batch.text\n",
        "    output=model(text, text_lengths).squeeze(1)\n",
        "    loss=criterion(output, batch.label)\n",
        "    acc=accuracy(output, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "    epoch_acc+=acc.item()\n",
        "\n",
        "  return epoch_loss/len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG8ZDaNnEylN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss=0.0\n",
        "  epoch_acc=0.0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch in iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      output=model(text, text_lengths).squeeze(1)\n",
        "      loss=criterion(output, batch.label)\n",
        "      acc=accuracy(output, batch.label)\n",
        "      \n",
        "      epoch_loss+=loss.item()\n",
        "      epoch_acc+=acc.item()\n",
        "\n",
        "  return epoch_loss/len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTE2IVoPGbqI",
        "colab_type": "code",
        "outputId": "0fd8748a-cefc-4d60-985a-c82016dfa8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "best_valid_loss=float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  train_loss, train_acc=train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc=evaluate(model, valid_iterator, optimizer, criterion)\n",
        "\n",
        "  if(valid_loss < best_valid_loss):\n",
        "    best_valid_loss=valid_loss\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "  \n",
        "  print(\"Epoch: \", epoch, \"train_loss: \", train_loss, \"valid_loss: \", valid_loss, \"train_acc: \", train_acc, \"valid_acc: \", valid_acc)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 train_loss:  0.6718334235498667 valid_loss:  0.6571473418656042 train_acc:  0.5867167519181585 valid_acc:  0.6202330508474576\n",
            "Epoch:  1 train_loss:  0.6199127686450548 valid_loss:  0.56934842214746 train_acc:  0.6587675831202046 valid_acc:  0.7292108050847458\n",
            "Epoch:  2 train_loss:  0.6158705341541554 valid_loss:  0.4776454699241509 train_acc:  0.6553388747107952 valid_acc:  0.780941031241821\n",
            "Epoch:  3 train_loss:  0.37520733925387684 valid_loss:  0.3764059850472515 train_acc:  0.8392343350383632 valid_acc:  0.8620674438395742\n",
            "Epoch:  4 train_loss:  0.2636686168096559 valid_loss:  0.27481875682281237 train_acc:  0.8924952045730923 valid_acc:  0.8832980227672448\n",
            "Epoch:  5 train_loss:  0.21901952532474953 valid_loss:  0.26300423674411694 train_acc:  0.9156010230179028 valid_acc:  0.8942884888689396\n",
            "Epoch:  6 train_loss:  0.19316890298405573 valid_loss:  0.27388044333053846 train_acc:  0.9254635549567239 valid_acc:  0.8964071329367362\n",
            "Epoch:  7 train_loss:  0.16989504102893802 valid_loss:  0.2636550677529836 train_acc:  0.9362212276214834 valid_acc:  0.8961423024282618\n",
            "Epoch:  8 train_loss:  0.14461974384706192 valid_loss:  0.28160369872920593 train_acc:  0.9488810741383097 valid_acc:  0.8899187854791092\n",
            "Epoch:  9 train_loss:  0.13407222563138857 valid_loss:  0.2948331080882226 train_acc:  0.9520220588845061 valid_acc:  0.8987906075130074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQLK5mAGeIln",
        "colab_type": "code",
        "outputId": "385f7e57-eea6-4ade-f371-fda5f2b77d02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "test_loss, test_acc=evaluate(model, test_iterator, optimizer, criterion)\n",
        "print(\"test_loss: \", test_loss, \"test_acc: \", test_acc*100)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss:  0.2542279395852646 test_acc:  89.66208291749884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DcStmy4u1fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}